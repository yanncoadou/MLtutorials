{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AstroInfo2021.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanncoadou/MLtutorials/blob/main/AstroInfo2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcL2rlpraCL2"
      },
      "source": [
        "<h1>AstroInfo 2021 Machine learning hands-on</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYV6fbcnXIR2"
      },
      "source": [
        "# Standard imports and practical functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HnV_PMdpCI7"
      },
      "source": [
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification, make_circles\n",
        "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, accuracy_score, roc_auc_score, roc_curve, RocCurveDisplay\n",
        "\n",
        "%matplotlib inline\n",
        "import seaborn as sns # seaborn for nice plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(31415) # set the np random seed for reproducibility"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATAV2LehCsHL"
      },
      "source": [
        "### Function to plot decision contours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBSIEt7OX2R8"
      },
      "source": [
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "def my_plot_decision_regions(model, X, y, alpha=1.0, size=25, npts=10000, zoom=0.25, event5=False):\n",
        "  x1min = X[:,0].min() - zoom\n",
        "  x1max = X[:,0].max() + zoom\n",
        "\n",
        "  x2min = X[:,1].min() - zoom\n",
        "  x2max = X[:,1].max() + zoom\n",
        "  \n",
        "  x1 = np.random.uniform(x1min, x1max, npts)\n",
        "  x2 = np.random.uniform(x2min, x2max, npts)\n",
        "\n",
        "  if hasattr(model, \"predict_proba\"):\n",
        "    z = model.predict_proba(np.vstack((x1,x2)).T)\n",
        "  else:\n",
        "    z = model.predict(np.vstack((x1,x2)).T)\n",
        "  \n",
        "  if len(z.shape) == 2:\n",
        "    if z.shape[1] == 1:\n",
        "      z = z.reshape(-1)\n",
        "    elif z.shape[1] == 2:\n",
        "      z = z[:,1].reshape(-1)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  bottom = cm.get_cmap('Oranges', 128)\n",
        "  top = cm.get_cmap('Blues_r', 128)\n",
        "\n",
        "  newcolors = np.vstack((top(np.linspace(0, 1, 128+128)[-128:]),\n",
        "                        bottom(np.linspace(0, 1, 128+128)[:128])))\n",
        "  newcmp = ListedColormap(newcolors, name='OrangeBlue')\n",
        "\n",
        "\n",
        "  ax.tricontour(x1, x2, z, levels=np.linspace(0.0-np.finfo(float).eps,1.0+np.finfo(float).eps,20,True), linewidths=0.1, colors='k', antialiased=True)\n",
        "  cntr = ax.tricontourf(x1, x2, z, levels=np.linspace(0.0-np.finfo(float).eps,1.0+np.finfo(float).eps,20,True), cmap=newcmp)\n",
        "  sctr0 = ax.scatter(X[y==0][:,0], X[y==0][:,1], alpha=alpha, s=size, c=\"#1f77b4\", marker=\"s\", edgecolors=\"k\", linewidths=0.5)\n",
        "  sctr1 = ax.scatter(X[y==1][:,0], X[y==1][:,1], alpha=alpha, s=size, c=\"#ff7f0e\",  marker=\"^\", edgecolors=\"k\", linewidths=0.5)\n",
        "  if event5: # showing particular swinger event\n",
        "    sctr2 = ax.scatter(X[4][0], X[4][1], alpha=1, s=size*10, c=\"lightgreen\",  marker=\"X\", edgecolors=\"k\", linewidths=1)\n",
        "  fig.colorbar(cntr, ax=ax)\n",
        "  # ax.set(xlim=(x1min, x1max), ylim=(x2min, x2max))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQWreSYyC63_"
      },
      "source": [
        "### Function to plot ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjBgEqYSf9ke"
      },
      "source": [
        "def my_plot_roc_curve(model, X_test, y_test):\n",
        "  if hasattr(model, \"predict_proba\"):\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "  else:\n",
        "    y_scores = model.predict(X_test)\n",
        "\n",
        "  if len(y_scores.shape) == 2:\n",
        "    if y_scores.shape[1] == 1:\n",
        "      y_scores = y_scores.reshape(-1)\n",
        "    elif y_scores.shape[1] == 2:\n",
        "      y_scores = y_scores[:,1].reshape(-1)\n",
        "  fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
        "  roc_auc = roc_auc_score(y_test, y_scores)\n",
        "  plt.clf()\n",
        "  display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=model.__class__.__name__)\n",
        "  display.plot()\n",
        "  plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftrjb9N0GPDU"
      },
      "source": [
        "# Defining datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTL8w9wsxHHJ"
      },
      "source": [
        "# X = (x,y) coordinates; y = class\n",
        "X1, y1 = make_circles(n_samples=1000, noise=0.1, factor=0.8)\n",
        "X2, y2 = make_circles(n_samples=1000, noise=0.2, factor=0.2)\n",
        "X = np.vstack((X1,X2/2))\n",
        "y = np.hstack((y1,y2))\n",
        "\n",
        "# Splitting in train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkZHLdFdEDSO"
      },
      "source": [
        "# Classifier zoo\n",
        "\n",
        "Play with various tree-based algorithms as implemented in scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xKG-csE30o1"
      },
      "source": [
        "## Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENciMbPgs1of"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZVxFAovs-aB"
      },
      "source": [
        "dtc = DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1TbTgmHpgO8"
      },
      "source": [
        "display(dtc.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I61-2OGO9tXD"
      },
      "source": [
        "dtc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6--R3vIsHx"
      },
      "source": [
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=(15,10))\n",
        "plot_tree(dtc)\n",
        "plt.show();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS3I8tf6rkIQ"
      },
      "source": [
        "---\n",
        "How often is the prediction of the decision tree correct? Measured with *accuracy*.\n",
        "\n",
        "Note: MANY other measures of performance, see e.g. what is available in [scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWtnH5mfHoAc"
      },
      "source": [
        "print(\"Accuracy:\",accuracy_score(y_test, dtc.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws6PLQDMXomi"
      },
      "source": [
        "---\n",
        "Access to results:\n",
        "- `predict` returns the class (0 or 1 if binary classifier)\n",
        "- `predict_proba` returns the probability of each class (if available)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMELaRV8WykV"
      },
      "source": [
        "print(\"predict: \\n\",dtc.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",dtc.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ebgN5Ciu_MU"
      },
      "source": [
        "try:\n",
        "  from mlxtend.plotting import plot_decision_regions\n",
        "except ImportError as e:\n",
        "  !pip install mlxtend\n",
        "  from mlxtend.plotting import plot_decision_regions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xQIXsMmvHqT"
      },
      "source": [
        "# practical but limited contour-plotting function\n",
        "plot_decision_regions(X_test, y_test, dtc);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_iWuFOEYTL5"
      },
      "source": [
        "# defined at top of notebook\n",
        "# can use class (0 or 1) or class probability when available\n",
        "my_plot_decision_regions(dtc, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KnNIVndumhX"
      },
      "source": [
        "---\n",
        "Receiver operating characteristic curve (ROC curve) and area under the curve (AUC).\n"
        "<img style=\"display: block; margin-left: auto; margin-right: auto; width: 50%;\" alt=\"Save\" width=\"30%\" src=\"https://raw.githubusercontent.com/yanncoadou/MLtutorials/main/ROCcurve.png\" >\n",
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUVu3GmISTi"
      },
      "source": [
        "my_plot_roc_curve(dtc, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7GDJuCPuzp"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBsjZC-1Puzt"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjkcRs55Puzx"
      },
      "source": [
        "#abc = AdaBoostClassifier()\n",
        "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),n_estimators=100)\n",
        "display(abc.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759JYRk4-eRa"
      },
      "source": [
        "abc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ANOY5aZYMK7"
      },
      "source": [
        "print(\"predict: \\n\",abc.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",abc.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7EfSiKPuz6"
      },
      "source": [
        "my_plot_decision_regions(abc, X_test, y_test)\n",
        "my_plot_roc_curve(abc, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQOs0B2ahQZc"
      },
      "source": [
        "## Gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA3nD4rov9F5"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5RhTx8fv_jj"
      },
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=400,verbose=1)\n",
        "display(gbc.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUSc5Vyf_2Dw"
      },
      "source": [
        "gbc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_92fwlWPYxyk"
      },
      "source": [
        "print(\"predict: \\n\",gbc.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",gbc.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e27dSIbwwkUT"
      },
      "source": [
        "my_plot_decision_regions(gbc, X_test, y_test, event5=True)\n",
        "my_plot_roc_curve(gbc, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8k241SKLPiV"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaIRJLaTLPiZ"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvj_qdQILPib"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=400,verbose=1)\n",
        "display(rfc.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBNo7-VBKeu"
      },
      "source": [
        "rfc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtq-96fBe4c7"
      },
      "source": [
        "print(\"predict: \\n\",rfc.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",rfc.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9WlAQvDLPie"
      },
      "source": [
        "my_plot_decision_regions(rfc, X_test, y_test)\n",
        "my_plot_roc_curve(rfc, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p6edHiVc4Id"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGSnlX_yLPif"
      },
      "source": [
        "y_preds_dtc = dtc.predict_proba(X_test)[:,1].reshape(-1)\n",
        "y_preds_abc = abc.predict_proba(X_test)[:,1].reshape(-1)\n",
        "y_preds_gbc = gbc.predict_proba(X_test)[:,1].reshape(-1)\n",
        "y_preds_rfc = rfc.predict_proba(X_test)[:,1].reshape(-1)\n",
        "fpr_dtc,tpr_dtc,_ = roc_curve(y_true=y_test, y_score=y_preds_dtc)\n",
        "fpr_abc,tpr_abc,_ = roc_curve(y_true=y_test, y_score=y_preds_abc)\n",
        "fpr_gbc,tpr_gbc,_ = roc_curve(y_true=y_test, y_score=y_preds_gbc)\n",
        "fpr_rfc,tpr_rfc,_ = roc_curve(y_true=y_test, y_score=y_preds_rfc)\n",
        "auc_test_dtc = roc_auc_score(y_true=y_test, y_score=y_preds_dtc)\n",
        "auc_test_abc = roc_auc_score(y_true=y_test, y_score=y_preds_abc)\n",
        "auc_test_gbc = roc_auc_score(y_true=y_test, y_score=y_preds_gbc)\n",
        "auc_test_rfc = roc_auc_score(y_true=y_test, y_score=y_preds_rfc)\n",
        "plt.plot(fpr_dtc, tpr_dtc, color='darkblue',label='{} (AUC  = {})'.format(dtc.__class__.__name__,np.round(auc_test_dtc,decimals=2)))\n",
        "plt.plot(fpr_abc, tpr_abc, color='darkred',label='{} (AUC  = {})'.format(abc.__class__.__name__,np.round(auc_test_abc,decimals=2)))\n",
        "plt.plot(fpr_gbc, tpr_gbc, color='darkgreen',label='{} (AUC  = {})'.format(gbc.__class__.__name__,np.round(auc_test_gbc,decimals=2)))\n",
        "plt.plot(fpr_rfc, tpr_rfc, color='darkorange',label='{} (AUC  = {})'.format(rfc.__class__.__name__,np.round(auc_test_rfc,decimals=2)))\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHtukkcHSSN"
      },
      "source": [
        "## Other classifiers\n",
        "We have only seen tree-based classifiers from scikit-learn above. There are many more types of classifiers:\n",
        "\n",
        "1.   implemented in scikit-learn: see the [user's guide](https://scikit-learn.org/stable/user_guide.html) for A LOT of different algorithms\n",
        "2.   in various other packages:\n",
        "- for decision trees: [XGBoost](https://xgboost.readthedocs.io/en/stable/), [LightGBM](https://lightgbm.readthedocs.io/en/latest/), [CatBoost](https://catboost.ai/)\n",
        "\n",
        "- for neural networks: [TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnOE-0N_fdIx"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgqAzaX_W_uK"
      },
      "source": [
        "# preinstalled version 0.9.0 20211119\n",
        "!pip install xgboost --upgrade # install 1.5.0 20211119"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM4NNbJoPZN_"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "# tree_method=\"hist\" is 10 times faster, however less robust against awkwards features (not a bad idea to double check without it)\n",
        "# can even try tree_method=\"gpu_hist\" if proper GPU installation\n",
        "# use_label_encoder and eval_metric to silence warning in >1.3.0\n",
        "xgb = XGBClassifier(tree_method=\"hist\",use_label_encoder=False,eval_metric='logloss')\n",
        "\n",
        "xgb.fit(X_train, y_train) # note that XGB 1.3.X requires positive weights\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvpqMZ1-TpUd"
      },
      "source": [
        "print(\"predict: \\n\",xgb.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",xgb.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD3734bnQzZH"
      },
      "source": [
        "y_preds_xgb = xgb.predict_proba(X_test)[:,1].reshape(-1)\n",
        "fpr_xgb,tpr_xgb,_ = roc_curve(y_true=y_test, y_score=y_preds_xgb)\n",
        "auc_test_xgb = roc_auc_score(y_true=y_test, y_score=y_preds_xgb)\n",
        "plt.plot(fpr_rfc, tpr_rfc, color='darkorange',label='{} (AUC  = {})'.format(rfc.__class__.__name__,np.round(auc_test_rfc,decimals=2)))\n",
        "plt.plot(fpr_xgb, tpr_xgb, color='purple',label='{} (AUC  = {})'.format(\"XGBoost\",np.round(auc_test_xgb,decimals=2)))\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVR4ywDEim1Q"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8XlCk0X6xj"
      },
      "source": [
        "# preinstalled version 2.2.3 20211119\n",
        "!pip install lightgbm --upgrade # install 3.3.1 20211119\n",
        "import lightgbm as lgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDbUCYMOUbPA"
      },
      "source": [
        "gbm = lgb.LGBMClassifier()\n",
        "gbm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAaxHkU6Uwv3"
      },
      "source": [
        "print(\"predict: \\n\",gbm.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",gbm.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE7APbcwU904"
      },
      "source": [
        "y_preds_gbm = gbm.predict_proba(X_test)[:,1].reshape(-1)\n",
        "fpr_gbm,tpr_gbm,_ = roc_curve(y_true=y_test, y_score=y_preds_gbm)\n",
        "auc_test_gbm = roc_auc_score(y_true=y_test, y_score=y_preds_gbm)\n",
        "plt.plot(fpr_rfc, tpr_rfc, color='darkorange',label='{} (AUC  = {})'.format(rfc.__class__.__name__,np.round(auc_test_rfc,decimals=2)))\n",
        "plt.plot(fpr_xgb, tpr_xgb, color='purple',label='{} (AUC  = {})'.format(\"XGBoost\",np.round(auc_test_xgb,decimals=2)))\n",
        "plt.plot(fpr_gbm, tpr_gbm, color='darkgreen',label='{} (AUC  = {})'.format(\"LightGBM\",np.round(auc_test_gbm,decimals=2)))\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvLySceMI4cT"
      },
      "source": [
        "### CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1PUtBnUI4cZ"
      },
      "source": [
        "# not preinstalled 20211119\n",
        "!pip install catboost # install 1.0.3 20211119\n",
        "import catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCORGF2tVmRF"
      },
      "source": [
        "cat = catboost.CatBoostClassifier()\n",
        "cat.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFCV1iAaVmRL"
      },
      "source": [
        "print(\"predict: \\n\",cat.predict(X_test[:5]))\n",
        "print(\"predict_proba: \\n\",cat.predict_proba(X_test[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QI4MDnfVmRR"
      },
      "source": [
        "y_preds_cat = cat.predict_proba(X_test)[:,1].reshape(-1)\n",
        "fpr_cat,tpr_cat,_ = roc_curve(y_true=y_test, y_score=y_preds_cat)\n",
        "auc_test_cat = roc_auc_score(y_true=y_test, y_score=y_preds_cat)\n",
        "plt.plot(fpr_rfc, tpr_rfc, color='darkorange',label='{} (AUC  = {})'.format(rfc.__class__.__name__,np.round(auc_test_rfc,decimals=2)))\n",
        "plt.plot(fpr_xgb, tpr_xgb, color='purple',label='{} (AUC  = {})'.format(\"XGBoost\",np.round(auc_test_xgb,decimals=2)))\n",
        "plt.plot(fpr_gbm, tpr_gbm, color='darkgreen',label='{} (AUC  = {})'.format(\"LightGBM\",np.round(auc_test_gbm,decimals=2)))\n",
        "plt.plot(fpr_cat, tpr_cat, color='red',label='{} (AUC  = {})'.format(\"CatBoost\",np.round(auc_test_cat,decimals=2)))\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNk6hXogjTyP"
      },
      "source": [
        "# Cosmology application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlvdR4dA4hcP"
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  COLAB = True # if running in COLAB\n",
        "except:\n",
        "  COLAB = False # if not running on COLAB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0TmE1VLlxyG"
      },
      "source": [
        "## Input dataset\n",
        "\n",
        "Setting up access to data files on Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PqZCKlVSMJ"
      },
      "source": [
        "### Mount Drive\n",
        "\n",
        "If you followed pre-AstroInfo instructions, you have already validated access to the folder. If not: before mounting your Google Drive click on [this folder](https://drive.google.com/drive/folders/1PcftgBzBySo1Ync-Wdsp9arTCJ_MfEPE?usp=sharing) and add it to your Google Drive by following these steps:\n",
        "\n",
        "*   Go to your [Drive ](https://drive.google.com)\n",
        "*   Find shared folder (\"Shared with me\" link)\n",
        "*   Right click on it\n",
        "*   Click Add to My Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Io82GXlCNdF"
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  pathinData=\"/content/drive/My Drive/EDE21/morphology\"\n",
        "else:\n",
        "  # You have to make sure to get the input files locally.\n",
        "  # Files of interest for this session:\n",
        "  #   EDE21/morphology/feature_E_S.npy\n",
        "  #   EDE21/morphology/label_E_S.npy\n",
        "  # from the Drive folder reported above\n",
        "  pathinData=\"/directory/where/you/stored/{feature,label}_E_S.npy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fENt2OsTRWy0"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dwLGPyqey_z"
      },
      "source": [
        "import numpy as np\n",
        "# donwload feature vector and labels\n",
        "X_ML = np.load(pathinData+'/feature_E_S_large.npy')\n",
        "#morphological class\n",
        "Y_ML = np.load(pathinData+'/label_E_S_large.npy')\n",
        "print (\"\\nFiles loaded with\",X_ML.shape[0], \"galaxies \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5fuSNIa33Nj"
      },
      "source": [
        "If accessing the files properly, you should now see:\n",
        "\n",
        "`File loaded with 11489 galaxies`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iA5CK6DmhPi"
      },
      "source": [
        "### Switching from numpy to pandas\n",
        "\n",
        "Just to play a bit with pandas. Input files are in numpy binary format, with no header. Let's fix this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROMhtcGHZLbc"
      },
      "source": [
        "import pandas as pd\n",
        "columns=['Colour','Mass','SersicIndex', 'VelocityDispersion','AxisRatio']\n",
        "dfall=pd.DataFrame(X_ML,columns=columns)\n",
        "#target=pd.DataFrame(Y_ML,columns=['Label'],dtype=np.uint) # trick to read label as 0/1\n",
        "#target=pd.DataFrame(Y_ML,columns=['Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms_kAr_nmWL3"
      },
      "source": [
        "### Checking the content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKOBCbam1pD"
      },
      "source": [
        "#dumping list of features\n",
        "dfall.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC3MydYcnBzE"
      },
      "source": [
        "#examining first few galaxies\n",
        "display(dfall.head())\n",
        "display(Y_ML)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb-Pv4TXnNPQ"
      },
      "source": [
        "#examining feature distributions\n",
        "dfall.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38t5fWDRf967"
      },
      "source": [
        "## Event selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEzVz2fUvUNs"
      },
      "source": [
        "### Plotting variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16cH0csMjoLZ"
      },
      "source": [
        "fig,ax=plt.subplots(1, 2, figsize=(12, 5))\n",
        "dfall['Mass'].plot.hist(title='$Log(M_*)$', log=True, ax=ax[0])\n",
        "dfall[dfall.Colour>0.1]['Mass'].plot.hist(bins=np.linspace(8,12,50),title='$Log(M_*)$ for Colour>0.2', ax=ax[1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqwSM579lxQI"
      },
      "source": [
        "ax=dfall[Y_ML==0].plot.scatter(x='Mass', y='Colour',color=\"b\",label=\"Morph0\")\n",
        "dfall[Y_ML==1].plot.scatter(x='Mass', y='Colour',color=\"r\",label=\"Morph1\",alpha=.1,ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lFsOPQfvpK7"
      },
      "source": [
        "ax=dfall[Y_ML==0].hist(figsize=(15,12),bins=50,color='b',alpha=0.5,density=True,label=\"Morph0\")\n",
        "ax=ax.flatten()[:dfall.shape[1]] # to avoid error if holes in the grid of plots (like if 7 or 8 features)\n",
        "dfall[Y_ML==1].hist(figsize=(15,12),bins=50,color='r',alpha=0.5,density=True,ax=ax,label=\"Morph1\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5o3BdN0vWRS"
      },
      "source": [
        "### Feature engineering\n",
        "\n",
        "Add more complex variables to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgeyQKNgvkOx"
      },
      "source": [
        "# adding new variables\n",
        "dfall[\"CrazyVar\"]=dfall.Colour * dfall.AxisRatio\n",
        "\n",
        "print (dfall.shape)\n",
        "display(dfall.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2wvNoDqgDPq"
      },
      "source": [
        "# Select events with Colour > 0.1\n",
        "print (\"DataFrame shape before selection:\", dfall.shape)\n",
        "\n",
        "fulldata=dfall[dfall.Colour > 0.1]\n",
        "# do not forget to synchronise other arrays!\n",
        "target=Y_ML[dfall.Colour > 0.1]\n",
        "\n",
        "print (\"DataFrame shape after selection: \",fulldata.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM01cgNliKeV"
      },
      "source": [
        "# Keeping only a subset of features\n",
        "data=pd.DataFrame(fulldata, columns=['Colour','Mass','SersicIndex', 'VelocityDispersion','AxisRatio'])\n",
        "\n",
        "print (\"DataFrame shape of dataset to be used:\",data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw3xGtyYVoRm"
      },
      "source": [
        "### Features correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "DYCWyOalVoRn"
      },
      "source": [
        "fig,ax=plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "corrMatrix = data[target==0].corr()\n",
        "ax[0].set_title(\"Morph0 features correlation matrix\")\n",
        "sns.heatmap(corrMatrix.round(3), ax=ax[0], annot=True);\n",
        "\n",
        "corrMatrix = data[target==1].corr()\n",
        "ax[1].set_title(\"Morph1 features correlation matrix\")\n",
        "sns.heatmap(corrMatrix.round(3), ax=ax[1], annot=True);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iekW3mH_2bv4"
      },
      "source": [
        "## Sample splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd_EetqH2XRo"
      },
      "source": [
        "np.random.seed(31415) # set the random seed (used for the train/test splitting)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_size = 0.75 # fraction of sample used for training\n",
        "val_size = 0.2 # fraction of training sample used for validation\n",
        "\n",
        "# split only train/test\n",
        "#X_train, X_test, y_train, y_test, weights_train, weights_test = \\\n",
        "#    train_test_split(data, target, weights, train_size=train_size)\n",
        "\n",
        "#split in train/validation/test\n",
        "X_holdout, X_test, y_holdout, y_test = \\\n",
        "    train_test_split(data, target, train_size=train_size)\n",
        "X_train, X_val, y_train, y_val = \\\n",
        "    train_test_split(X_holdout, y_holdout, train_size=1-val_size)\n",
        "\n",
        "print(\"Training sample:  \", X_train.shape)\n",
        "print(\"Validation sample:\", X_val.shape)\n",
        "print(\"Testing sample:   \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyEFjed1EJmc"
      },
      "source": [
        "## ML algorithms training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvkMyyLUNTT"
      },
      "source": [
        "np.random.seed(31415) # set the random seed\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score # for binary classification if x > 0.5 -> 1 else -> 0\n",
        "# tree_method=\"hist\" is 10 times faster, however less robust against awkwards features (not a bad idea to double check without it)\n",
        "# can even try tree_method=\"gpu_hist\" if proper GPU installation\n",
        "# use_label_encoder and eval_metric to silence warning in 1.3.0\n",
        "xgb = XGBClassifier(tree_method=\"hist\",use_label_encoder=False,eval_metric='logloss')\n",
        "# HPO (==Hyper Parameter Optimization), check on the web https://xgboost.readthedocs.io/ for other parameters\n",
        "#xgb = XGBClassifier(tree_method=\"hist\",use_label_encoder=False,max_depth=10,n_estimators=100) \n",
        "\n",
        "import time\n",
        "starting_time = time.time()\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "        \n",
        "training_time = time.time( ) - starting_time\n",
        "print(\"Training time:\",training_time)\n",
        "\n",
        "y_pred_xgb = xgb.predict_proba(X_test)[:,1].ravel()\n",
        "y_pred_train_xgb = xgb.predict_proba(X_train)[:,1].ravel()\n",
        "auc_test_xgb = roc_auc_score(y_true=y_test, y_score=y_pred_xgb)\n",
        "print(\"AUC test: \",np.round(auc_test_xgb,decimals=3))\n",
        "print (\"AUC train:\",np.round(roc_auc_score(y_true=y_train, y_score=y_pred_train_xgb),decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMI4RQAhEVZP"
      },
      "source": [
        "### Standardisation of inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHW-U78IFdeS"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"Original mean and variance:\")\n",
        "for feature, mean, std in zip(data.columns,X_train.mean(0), X_train.std(0)):\n",
        "  print(\"{:9}: {:7.4f} +/- {:7.4f}\".format(feature,mean,std))\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "# in training sample\n",
        "scaler = StandardScaler()\n",
        "# \".values[:]\" to keep dataframe and not convert to numpy array\n",
        "X_train.values[:] = scaler.fit_transform(X_train)\n",
        "# apply to testing/validation sample the transformation calculated on training sample\n",
        "X_test.values[:] = scaler.transform(X_test)\n",
        "X_val.values[:] = scaler.transform(X_val)\n",
        "\n",
        "print(\"\\nStandardised mean and variance:\")\n",
        "for feature, mean, std in zip(data.columns,X_train.mean(0), X_train.std(0)):\n",
        "  print(\"{:9}: {:7.4f} +/- {:7.4f}\".format(feature,mean,std))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp2cLwg3a7Ao"
      },
      "source": [
        "np.random.seed(31415) # reset the random seed\n",
        "\n",
        "# redefine the same classifier\n",
        "xgb = XGBClassifier(tree_method=\"hist\",use_label_encoder=False,eval_metric='logloss')\n",
        "\n",
        "starting_time = time.time()\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "      \n",
        "training_time = time.time( ) - starting_time\n",
        "print(\"Training time:\",training_time)\n",
        "\n",
        "y_pred_xgb = xgb.predict_proba(X_test)[:,1].ravel()\n",
        "y_pred_train_xgb = xgb.predict_proba(X_train)[:,1].ravel()\n",
        "auc_test_xgb = roc_auc_score(y_true=y_test, y_score=y_pred_xgb)\n",
        "print(\"AUC test: \",np.round(auc_test_xgb,decimals=3))\n",
        "print (\"AUC train:\",np.round(roc_auc_score(y_true=y_train, y_score=y_pred_train_xgb),decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f842cWRvMBnV"
      },
      "source": [
        "Compare performance with previous training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8IqX99nRvwi"
      },
      "source": [
        "my_plot_roc_curve(xgb, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnjgYUWN5o-V"
      },
      "source": [
        "density=True   # normalised to 1 (=> probability density function)\n",
        "#density=False   # based on test file class balance\n",
        "\n",
        "plt.hist(y_pred_xgb[y_test == 0],\n",
        "         color='b', alpha=0.5, \n",
        "         bins=30,\n",
        "         histtype='stepfilled', density=density,\n",
        "         label='Morph0 (test)')\n",
        "plt.hist(y_pred_xgb[y_test == 1],\n",
        "         color='r', alpha=0.5,\n",
        "         bins=30,\n",
        "         histtype='stepfilled', density=density,\n",
        "         label='Morph1 (test)')\n",
        "plt.legend()\n",
        "plt.title(\"XGBoost score\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4cTdFbz7gFW"
      },
      "source": [
        "### Training monitoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8iTUmU4ydUw"
      },
      "source": [
        "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
        "\n",
        "# previous training command line:\n",
        "#  xgb.fit(X_train, y_train)\n",
        "\n",
        "xgb.fit(X_train, y_train, eval_metric=[\"logloss\",\"auc\",\"error\"], eval_set=eval_set)\n",
        "\n",
        "## Adding early stopping condition\n",
        "#xgb.fit(X_train, y_train, eval_metric=[\"logloss\",\"auc\",\"error\"], eval_set=eval_set, early_stopping_rounds=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdGYPNAsknR_"
      },
      "source": [
        "# retrieve performance metrics\n",
        "results = xgb.evals_result()\n",
        "epochs = len(results['validation_0']['error'])\n",
        "x_axis = range(0, epochs)\n",
        "# plot log loss\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
        "ax.plot(x_axis, results['validation_1']['logloss'], label='Validation')\n",
        "ax.legend()\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title('XGBoost Log Loss')\n",
        "plt.show()\n",
        "# plot classification error\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
        "ax.plot(x_axis, results['validation_1']['error'], label='Validation')\n",
        "ax.legend()\n",
        "plt.ylabel('Classification Error')\n",
        "plt.title('XGBoost Classification Error')\n",
        "plt.show()\n",
        "# plot AUC\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x_axis, results['validation_0']['auc'], label='Train')\n",
        "ax.plot(x_axis, results['validation_1']['auc'], label='Validation')\n",
        "ax.legend()\n",
        "plt.ylabel('AUC')\n",
        "plt.title('XGBoost Area under the curve (AUC)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R606WhZ9lGt"
      },
      "source": [
        "###Learning curve\n",
        "Compute the AUC by varying the number of training events. Validation set remains the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2FGlKG6yjy-"
      },
      "source": [
        "train_sizes=[0.01,0.05,0.1,0.2,0.5,0.75,1]\n",
        "ntrains=[]\n",
        "val_aucs=[]\n",
        "train_aucs=[]\n",
        "times=[]\n",
        "\n",
        "for train_size in train_sizes:\n",
        "  ntrain=int(len(X_train)*train_size)\n",
        "  print(\"Training with \",ntrain,\" events\")\n",
        "  ntrains+=[ntrain]\n",
        "  starting_time = time.time()\n",
        "\n",
        "  # train using the first ntrain event of the training dataset\n",
        "  xgb.fit(X_train[:ntrain], y_train[:ntrain])\n",
        "  training_time = time.time( ) - starting_time\n",
        "  times+=[training_time]\n",
        "\n",
        "  # score on validation dataset (always the same)\n",
        "  y_val_xgb=xgb.predict_proba(X_val)[:,1]\n",
        "  auc_val_xgb = roc_auc_score(y_true=y_val, y_score=y_val_xgb)\n",
        "  val_aucs+=[auc_val_xgb]\n",
        "\n",
        "  # score on the train dataset \n",
        "  y_train_xgb=xgb.predict_proba(X_train[:ntrain])[:,1]\n",
        "  auc_train_xgb = roc_auc_score(y_true=y_train[:ntrain], y_score=y_train_xgb)\n",
        "  train_aucs+=[auc_train_xgb]\n",
        "\n",
        "dflearning=pd.DataFrame({\"Ntraining\":ntrains,\n",
        "                         \"val_auc\":val_aucs,\n",
        "                         \"train_auc\":train_aucs,\n",
        "                         \"time\":times})\n",
        "display(dflearning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-G75wEil_q-"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(12, 5))\n",
        "ax[0].grid()\n",
        "ax[0].plot('Ntraining','train_auc',\"o-\",data=dflearning,label=\"Train\",color=\"r\")\n",
        "ax[0].plot(dflearning.Ntraining,dflearning.val_auc,\"o-\",label=\"Validation\",color=\"b\")\n",
        "ax[0].set_xlabel(\"Training examples\")\n",
        "ax[0].set_ylabel(\"AUC\")\n",
        "ax[0].legend()\n",
        "ax[1].grid()\n",
        "ax[1].plot('Ntraining','time',\"o-\",data=dflearning)\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Training examples\")\n",
        "ax[1].set_ylabel(\"Fit time [s]\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzCKxGXHjgTh"
      },
      "source": [
        "Could also use `learning_curve` in sklearn\n",
        "\n",
        "*Notes*:\n",
        "* it does not handle event weights\n",
        "* it does not allow to control testing dataset size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qygIGQDhfXNd"
      },
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "train_sizes,train_scores,test_scores,fit_times,_=learning_curve(\n",
        "     XGBClassifier(tree_method=\"hist\",use_label_encoder=False,eval_metric='logloss'),\n",
        "     X_train,y_train,\n",
        "     train_sizes=[0.01,0.05,0.1,0.2,0.5,0.75,1],                  \n",
        "     scoring='roc_auc',cv=5,\n",
        "     return_times=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFyLSJctfg-s"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(12, 5))\n",
        "ax[0].set_title('Learning curves')\n",
        "ax[0].set_xlabel(\"Training examples\")\n",
        "ax[0].set_ylabel(\"AUC\")\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "fit_times_mean = np.mean(fit_times, axis=1)\n",
        "fit_times_std = np.std(fit_times, axis=1)\n",
        "ax[0].grid()\n",
        "ax[0].fill_between(\n",
        "        train_sizes,\n",
        "        train_scores_mean - train_scores_std,\n",
        "        train_scores_mean + train_scores_std,\n",
        "        alpha=0.3,\n",
        "        color=\"r\",\n",
        ")\n",
        "ax[0].fill_between(\n",
        "        train_sizes,\n",
        "        test_scores_mean - test_scores_std,\n",
        "        test_scores_mean + test_scores_std,\n",
        "        alpha=0.3,\n",
        "        color=\"b\",\n",
        ")\n",
        "ax[0].plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Train\")\n",
        "ax[0].plot(train_sizes, test_scores_mean, \"o-\", color=\"b\", label=\"Validation\")\n",
        "ax[0].legend(loc=\"best\");\n",
        "\n",
        "# Plot fit time vs Ntraining\n",
        "ax[1].grid()\n",
        "ax[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
        "ax[1].fill_between(\n",
        "        train_sizes,\n",
        "        fit_times_mean - fit_times_std,\n",
        "        fit_times_mean + fit_times_std,\n",
        "        alpha=0.3,\n",
        ")\n",
        "ax[1].set_xlabel(\"Training examples\")\n",
        "ax[1].set_ylabel(\"Fit time [s]\")\n",
        "ax[1].set_title(\"Scalability of model\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvY8OfksdT08"
      },
      "source": [
        "### Model saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09els9DAcNP4"
      },
      "source": [
        "xgb.save_model(\"XGBoost.model\")\n",
        "!ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RRXtTz74H1t"
      },
      "source": [
        "Reload a trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIb7O2S3cbyY"
      },
      "source": [
        "print(\"Prediction from original model:\")\n",
        "display(xgb.predict_proba(X_test[:5]))\n",
        "\n",
        "reloaded_model=XGBClassifier()\n",
        "reloaded_model.load_model(\"XGBoost.model\")\n",
        "print(\"Prediction from reloaded model:\")\n",
        "display(reloaded_model.predict_proba(X_test[:5]))\n",
        "\n",
        "try:\n",
        "  np.testing.assert_allclose(\n",
        "      xgb.predict_proba(X_test), reloaded_model.predict_proba(X_test)\n",
        "  )\n",
        "  print(\"Original and reloaded models are identical\")\n",
        "except AssertionError:\n",
        "  print(\"Watch out: original and reloaded models are different\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWsfyeZzjS9"
      },
      "source": [
        "## Physics performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YniuFUBNMeQ"
      },
      "source": [
        "### Feature importance\n",
        "Feature importance allows to display the importance of each feature without rerunnning the training. It is obtained from internal algorithm quantities, like cumulated decrease of impurity, *during training*. Magnitude is arbitrary. It can be used as a not very reliable indication of which features are the most discriminant *for this particular training*.\n",
        "\n",
        "Very straightforward with decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkTl8I8PyMi"
      },
      "source": [
        "xgb = XGBClassifier(tree_method=\"hist\",use_label_encoder=False,eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHVWv_f5NMeR"
      },
      "source": [
        "plt.bar(data.columns.values, xgb.feature_importances_)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Feature importance\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWXVHA_8g4gx"
      },
      "source": [
        "*What about a different tree classifier?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFQEL8hnNEcg"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbc = GradientBoostingClassifier(n_estimators=10)\n",
        "gbc.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z04B3jCjjSZj"
      },
      "source": [
        "import lightgbm as lgb\n",
        "gbm = lgb.LGBMClassifier()\n",
        "gbm.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg2PoX9w76Dg"
      },
      "source": [
        "import catboost\n",
        "cat = catboost.CatBoostClassifier()\n",
        "cat.fit(X_train, y_train, verbose=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gQm1QEQ4aY"
      },
      "source": [
        "fig,ax=plt.subplots(2, 2, figsize=(18, 10))\n",
        "ax[0,0].bar(data.columns.values, xgb.feature_importances_)\n",
        "#ax[0,0].tick_params(labelrotation=45)\n",
        "ax[0,0].set_title(\"XGBoost feature importance\")\n",
        "ax[0,1].bar(data.columns.values, gbc.feature_importances_)\n",
        "#ax[0,1].tick_params(labelrotation=90)\n",
        "ax[0,1].set_title(\"sklearn feature importance\");\n",
        "ax[1,0].bar(data.columns.values, gbm.feature_importances_)\n",
        "#ax[1,0].tick_params(labelrotation=90)\n",
        "ax[1,0].set_title(\"LightGBM feature importance\");\n",
        "ax[1,1].bar(data.columns.values, cat.feature_importances_)\n",
        "#ax[1,1].tick_params(labelrotation=90)\n",
        "ax[1,1].set_title(\"CatBoost feature importance\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xPybEujNMeS"
      },
      "source": [
        "### Permutation importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiPAfpWquvqP"
      },
      "source": [
        "A better way to show the importance of each feature is Permutation Importance, where each feature in turn is replaced by an instance of an other event (effectively switching it off by randomising).\n",
        "\n",
        "Works on any classifier, not just DT-based. Can be estimated on any sample, not just training set.\n",
        "\n",
        "However, report can be misleading in case of highly correlated variables.\n",
        "\n",
        "Available in [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html).\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZb-TCA879lg"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "result_xgb = permutation_importance(xgb, X_val, y_val, n_repeats=1, random_state=42, n_jobs=2)\n",
        "forest_importances_xgb = pd.Series(result_xgb.importances_mean, index=list(data.columns.values))\n",
        "\n",
        "result_gbc = permutation_importance(gbc, X_val, y_val, n_repeats=1, random_state=42, n_jobs=2)\n",
        "forest_importances_gbc = pd.Series(result_gbc.importances_mean, index=list(data.columns.values))\n",
        "\n",
        "result_gbm = permutation_importance(gbm, X_val, y_val, n_repeats=1, random_state=42, n_jobs=2)\n",
        "forest_importances_gbm = pd.Series(result_gbm.importances_mean, index=list(data.columns.values))\n",
        "\n",
        "result_cat = permutation_importance(cat, X_val, y_val, n_repeats=1, random_state=42, n_jobs=2)\n",
        "forest_importances_cat = pd.Series(result_cat.importances_mean, index=list(data.columns.values))\n",
        "\n",
        "fig,ax=plt.subplots(2, 2, figsize=(18, 10))\n",
        "forest_importances_xgb.plot.bar(ax = ax[0,0], subplots=True)\n",
        "ax[0,0].set_title(\"XGBoost permutation importance\")\n",
        "forest_importances_gbc.plot.bar(ax = ax[0,1], subplots=True)\n",
        "ax[0,1].set_title(\"sklearn permutation importance\")\n",
        "forest_importances_gbm.plot.bar(ax = ax[1,0], subplots=True)\n",
        "ax[1,0].set_title(\"LightGBM permutation importance\")\n",
        "forest_importances_cat.plot.bar(ax = ax[1,1], subplots=True)\n",
        "ax[1,1].set_title(\"CatBoost permutation importance\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEoxOIiCuvqM"
      },
      "source": [
        "### Hyperparameter optimisation\n",
        "Can be done by hand, with [random search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) or [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
        "\n",
        "Also dedicated packages doing Gaussian process optimisation or 'tree of Parzen estimators' (TPE) (e.g. [hyperopt](https://github.com/hyperopt/hyperop) or [optuna](https://optuna.org/))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vSeMklV8uvqM"
      },
      "source": [
        "import scipy.stats as stats\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist_XGB = {'n_estimators': stats.randint(10, 500), #default 100\n",
        "                  'learning_rate': stats.uniform(0.01, 0.5), #def 0.3 \n",
        "                  'max_depth': stats.randint(3, 12)} # default 6\n",
        "\n",
        "# default CV is 5 fold, reduce to 2 for speed concern\n",
        "# default n_iter is 10 sets of parameters\n",
        "gsearch = RandomizedSearchCV(estimator = XGBClassifier(tree_method=\"hist\",use_label_encoder=False,eval_metric='logloss'), \n",
        "                             param_distributions = param_dist_XGB, \n",
        "                             scoring='roc_auc',n_iter=10,cv=2,verbose=2)\n",
        "gsearch.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdgWnDS6Jqyg"
      },
      "source": [
        "print (\"Best parameters: \",gsearch.best_params_)\n",
        "print (\"Best score (on train dataset CV): \",gsearch.best_score_)\n",
        "# Best model directly accessible if refit=True (default)\n",
        "y_pred_gs = gsearch.predict_proba(X_test)[:,1]\n",
        "print(\"... corresponding score on test dataset: \",roc_auc_score(y_true=y_test, y_score=y_pred_gs))\n",
        "\n",
        "dfsearch=pd.DataFrame.from_dict(gsearch.cv_results_)\n",
        "display(dfsearch.head())\n",
        "\n",
        "fig,ax=plt.subplots(1, 3, figsize=(15, 5))\n",
        "dfsearch.plot(\"param_n_estimators\",\"mean_test_score\",yerr=\"std_test_score\",linestyle = 'None',marker=\"o\", ax=ax[0])\n",
        "ax[0].scatter(gsearch.best_params_['n_estimators'],gsearch.best_score_,color='red',marker=\"*\",s=100,zorder=5)\n",
        "dfsearch.plot(\"param_learning_rate\",\"mean_test_score\",yerr=\"std_test_score\",linestyle = 'None',marker=\"o\", ax=ax[1])\n",
        "ax[1].scatter(gsearch.best_params_['learning_rate'],gsearch.best_score_,color='red',marker=\"*\",s=100,zorder=5)\n",
        "dfsearch.plot(\"param_max_depth\",\"mean_test_score\",yerr=\"std_test_score\",linestyle = 'None',marker=\"o\", ax=ax[2])\n",
        "ax[2].scatter(gsearch.best_params_['max_depth'],gsearch.best_score_,color='red',marker=\"*\",s=100,zorder=5);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}